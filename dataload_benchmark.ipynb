{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building High Performance Data Pipelines with tf.Data and Google Cloud Storage\n",
    "\n",
    "This article goes throw the steps of building a high performance data input pipeline using Tensorflow and Google Cloud Storage.\n",
    "The concepts and techniques are evolved at each step, going from the slower to the fastest solution.\n",
    "\n",
    "This article uses the Stanford Dogs Dataset [1] with ~20000 images and 120 classes.\n",
    "\n",
    "[1] https://www.kaggle.com/jessicali9530/stanford-dogs-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark function\n",
    "\n",
    "The benchmark will measure the number of images ingested (read) per second from Cloud Storage to the host virtual machine. There are several ways to implement this calculation, but a simple function was used to iterate through the dataset and measure the time.\n",
    "\n",
    "The following python function ('timeit' function) from Tensorflow documentation [1] (as of 03/18/2020 - version 2.1) is used. Since tf.data.Dataset implements \\__iter__, it is possible to iterate on this data to observe the progression.\n",
    "\n",
    "[1] https://www.tensorflow.org/tutorials/load_data/images#performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's import Tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now import some additional libraries\n",
    "from numpy import zeros\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark function for dataset\n",
    "import time\n",
    "default_timeit_steps = 1000\n",
    "\n",
    "# Iterate through each element of a dataset. An element is a pair \n",
    "# of image and label.\n",
    "def timeit(ds: tf.data.TFRecordDataset, steps: int = default_timeit_steps, \n",
    "           batch_size: int = BATCH_SIZE) -> None:\n",
    "    \n",
    "    start = time.time()\n",
    "    it = iter(ds)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        batch = next(it)\n",
    "        \n",
    "        if i%10 == 0:\n",
    "            print('.',end='')\n",
    "    print()\n",
    "    end = time.time()\n",
    "    \n",
    "    duration = end-start\n",
    "    print(\"{} batches: {} s\".format(steps, duration))\n",
    "    print(\"{:0.5f} Images/s\".format(BATCH_SIZE*steps/duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create the Dataset using tf.data - Reading images individually\n",
    "\n",
    "All the images are located in a bucket in Google Cloud Storage (example: gs://cloud_bucket/label/image.jpeg).\\\n",
    "Labels are extracted (parsed) from the image name.\n",
    "\n",
    "In this first step, the dataset is created from the images file paths (gs://...), and labels are extracted and one-hot encoded.\n",
    "\n",
    "This dataset maps each image in the bucket individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "# Paths where images are located\n",
    "FILENAMES = 'gs://tf-data-pipeline/*/*.jpg'\n",
    "\n",
    "# Paths where labels can be parsed\n",
    "FOLDERS = 'gs://tf-data-pipeline/*'\n",
    "\n",
    "# Image resolution and shape\n",
    "RESOLUTION = (224,224)\n",
    "IMG_SHAPE=(224,224,3)\n",
    "\n",
    "# Batch size and tf.data AUTOTUNE\n",
    "BATCH_SIZE = 1\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels from folder's name and create a map to an ID\n",
    "def get_label_map(path: str) -> (dict, dict):\n",
    "    #list folders in this path\n",
    "    folders_name = tf.io.gfile.glob(path)\n",
    "\n",
    "    labels = []\n",
    "    for folder in folders_name:\n",
    "        labels.append(folder.split(sep='/')[-1])\n",
    "\n",
    "    # Generate a Label Map and Interted Label Map\n",
    "    label_map = {labels[i]:i for i in range(len(labels))}\n",
    "    inv_label_map = {i:labels[i] for i in range(len(labels))}\n",
    "    \n",
    "    return label_map, inv_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the image's labels\n",
    "def one_hot_encode(label_map: dict, filepath: list) -> dict:\n",
    "    dataset = dict()\n",
    "    \n",
    "    for i in range(len(filepath)):\n",
    "        encoding = zeros(len(label_map), dtype='uint8')\n",
    "        encoding[label_map[filepath[i].split(sep='/')[-2]]] = 1\n",
    "        \n",
    "        dataset.update({filepath[i]:list(encoding)})\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map, inv_label_map = get_label_map(FOLDERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n02085620-Chihuahua': 0,\n",
       " 'n02085782-Japanese_spaniel': 1,\n",
       " 'n02085936-Maltese_dog': 2,\n",
       " 'n02086079-Pekinese': 3,\n",
       " 'n02086240-Shih-Tzu': 4,\n",
       " 'n02086646-Blenheim_spaniel': 5,\n",
       " 'n02086910-papillon': 6,\n",
       " 'n02087046-toy_terrier': 7,\n",
       " 'n02087394-Rhodesian_ridgeback': 8,\n",
       " 'n02088094-Afghan_hound': 9,\n",
       " 'n02088238-basset': 10,\n",
       " 'n02088364-beagle': 11,\n",
       " 'n02088466-bloodhound': 12,\n",
       " 'n02088632-bluetick': 13,\n",
       " 'n02089078-black-and-tan_coonhound': 14,\n",
       " 'n02089867-Walker_hound': 15,\n",
       " 'n02089973-English_foxhound': 16,\n",
       " 'n02090379-redbone': 17,\n",
       " 'n02090622-borzoi': 18,\n",
       " 'n02090721-Irish_wolfhound': 19,\n",
       " 'n02091032-Italian_greyhound': 20,\n",
       " 'n02091134-whippet': 21,\n",
       " 'n02091244-Ibizan_hound': 22,\n",
       " 'n02091467-Norwegian_elkhound': 23,\n",
       " 'n02091635-otterhound': 24,\n",
       " 'n02091831-Saluki': 25,\n",
       " 'n02092002-Scottish_deerhound': 26,\n",
       " 'n02092339-Weimaraner': 27,\n",
       " 'n02093256-Staffordshire_bullterrier': 28,\n",
       " 'n02093428-American_Staffordshire_terrier': 29,\n",
       " 'n02093647-Bedlington_terrier': 30,\n",
       " 'n02093754-Border_terrier': 31,\n",
       " 'n02093859-Kerry_blue_terrier': 32,\n",
       " 'n02093991-Irish_terrier': 33,\n",
       " 'n02094114-Norfolk_terrier': 34,\n",
       " 'n02094258-Norwich_terrier': 35,\n",
       " 'n02094433-Yorkshire_terrier': 36,\n",
       " 'n02095314-wire-haired_fox_terrier': 37,\n",
       " 'n02095570-Lakeland_terrier': 38,\n",
       " 'n02095889-Sealyham_terrier': 39,\n",
       " 'n02096051-Airedale': 40,\n",
       " 'n02096177-cairn': 41,\n",
       " 'n02096294-Australian_terrier': 42,\n",
       " 'n02096437-Dandie_Dinmont': 43,\n",
       " 'n02096585-Boston_bull': 44,\n",
       " 'n02097047-miniature_schnauzer': 45,\n",
       " 'n02097130-giant_schnauzer': 46,\n",
       " 'n02097209-standard_schnauzer': 47,\n",
       " 'n02097298-Scotch_terrier': 48,\n",
       " 'n02097474-Tibetan_terrier': 49,\n",
       " 'n02097658-silky_terrier': 50,\n",
       " 'n02098105-soft-coated_wheaten_terrier': 51,\n",
       " 'n02098286-West_Highland_white_terrier': 52,\n",
       " 'n02098413-Lhasa': 53,\n",
       " 'n02099267-flat-coated_retriever': 54,\n",
       " 'n02099429-curly-coated_retriever': 55,\n",
       " 'n02099601-golden_retriever': 56,\n",
       " 'n02099712-Labrador_retriever': 57,\n",
       " 'n02099849-Chesapeake_Bay_retriever': 58,\n",
       " 'n02100236-German_short-haired_pointer': 59,\n",
       " 'n02100583-vizsla': 60,\n",
       " 'n02100735-English_setter': 61,\n",
       " 'n02100877-Irish_setter': 62,\n",
       " 'n02101006-Gordon_setter': 63,\n",
       " 'n02101388-Brittany_spaniel': 64,\n",
       " 'n02101556-clumber': 65,\n",
       " 'n02102040-English_springer': 66,\n",
       " 'n02102177-Welsh_springer_spaniel': 67,\n",
       " 'n02102318-cocker_spaniel': 68,\n",
       " 'n02102480-Sussex_spaniel': 69,\n",
       " 'n02102973-Irish_water_spaniel': 70,\n",
       " 'n02104029-kuvasz': 71,\n",
       " 'n02104365-schipperke': 72,\n",
       " 'n02105056-groenendael': 73,\n",
       " 'n02105162-malinois': 74,\n",
       " 'n02105251-briard': 75,\n",
       " 'n02105412-kelpie': 76,\n",
       " 'n02105505-komondor': 77,\n",
       " 'n02105641-Old_English_sheepdog': 78,\n",
       " 'n02105855-Shetland_sheepdog': 79,\n",
       " 'n02106030-collie': 80,\n",
       " 'n02106166-Border_collie': 81,\n",
       " 'n02106382-Bouvier_des_Flandres': 82,\n",
       " 'n02106550-Rottweiler': 83,\n",
       " 'n02106662-German_shepherd': 84,\n",
       " 'n02107142-Doberman': 85,\n",
       " 'n02107312-miniature_pinscher': 86,\n",
       " 'n02107574-Greater_Swiss_Mountain_dog': 87,\n",
       " 'n02107683-Bernese_mountain_dog': 88,\n",
       " 'n02107908-Appenzeller': 89,\n",
       " 'n02108000-EntleBucher': 90,\n",
       " 'n02108089-boxer': 91,\n",
       " 'n02108422-bull_mastiff': 92,\n",
       " 'n02108551-Tibetan_mastiff': 93,\n",
       " 'n02108915-French_bulldog': 94,\n",
       " 'n02109047-Great_Dane': 95,\n",
       " 'n02109525-Saint_Bernard': 96,\n",
       " 'n02109961-Eskimo_dog': 97,\n",
       " 'n02110063-malamute': 98,\n",
       " 'n02110185-Siberian_husky': 99,\n",
       " 'n02110627-affenpinscher': 100,\n",
       " 'n02110806-basenji': 101,\n",
       " 'n02110958-pug': 102,\n",
       " 'n02111129-Leonberg': 103,\n",
       " 'n02111277-Newfoundland': 104,\n",
       " 'n02111500-Great_Pyrenees': 105,\n",
       " 'n02111889-Samoyed': 106,\n",
       " 'n02112018-Pomeranian': 107,\n",
       " 'n02112137-chow': 108,\n",
       " 'n02112350-keeshond': 109,\n",
       " 'n02112706-Brabancon_griffon': 110,\n",
       " 'n02113023-Pembroke': 111,\n",
       " 'n02113186-Cardigan': 112,\n",
       " 'n02113624-toy_poodle': 113,\n",
       " 'n02113712-miniature_poodle': 114,\n",
       " 'n02113799-standard_poodle': 115,\n",
       " 'n02113978-Mexican_hairless': 116,\n",
       " 'n02115641-dingo': 117,\n",
       " 'n02115913-dhole': 118,\n",
       " 'n02116738-African_hunting_dog': 119}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files in bucket\n",
    "filepath = tf.io.gfile.glob(FILENAMES)\n",
    "NUM_TOTAL_IMAGES = len(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the features (image path) from labels\n",
    "dataset = one_hot_encode(label_map, filepath)\n",
    "dataset = [[k,v] for k,v in dataset.items()]\n",
    "\n",
    "features = [i[0] for i in dataset]\n",
    "labels = [i[1] for i in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset from Features and Labels\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'gs://tf-data-pipeline/n02085620-Chihuahua/n02085620_10074.jpg'>, <tf.Tensor: shape=(120,), dtype=int32, numpy=\n",
      "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "# Example of one element of the dataset\n",
    "# At this point we have a dataset containing the path and labels of an image\n",
    "print(next(iter(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define some preprocessing functions to:\n",
    " - Read the data from Cloud Storage\n",
    " - Decode JPEG\n",
    " - Convert image to a range between 0 and 1, as float\n",
    " - Resize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download image bytes from Cloud Storage\n",
    "def get_bytes_label(filepath, label):\n",
    "    raw_bytes = tf.io.read_file(filepath)\n",
    "    return raw_bytes, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Image\n",
    "def process_image(raw_bytes, label):\n",
    "    image = tf.io.decode_jpeg(raw_bytes, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    image = tf.image.resize(image, (224,224))\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buinding the dataset\n",
    "\n",
    "From the Dataset already built with image paths and labels, the preprocessing functions are applied to download the bytes from Cloud Storage and apply some transformations to the data. \\\n",
    "All of these steps are only performed when the dataset is iterated.\n",
    "\n",
    "At this point, all the steps are executed while streaming the data, including:\n",
    " - IO intensive operations like download de images (get_bytes_label)\n",
    " - CPU intensive operations like decode and resize the image (process_image)\n",
    "\n",
    "Since there are thousands of images, this process can take longer.\n",
    "\n",
    "Some observations:\n",
    " - \"num_parallel_calls = tf.data.experimental.AUTOTUNE\" was used to let tensorflow runtime decide the best parametrization for its functions.\\\n",
    " - \"dataset.cache\" was implemented, but as we are reading a large amount of data, this may not fit into memory and become impossible to use.\n",
    " - \"dataset.prefetch\" allows buffering of elements in order to increase performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map transformations for each element inside the dataset\n",
    "# Maps are separated as IO Intensive and CPU Intensive\n",
    "def build_dataset(dataset, batch_size=BATCH_SIZE, cache=False):\n",
    "    \n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            dataset = dataset.cache(cache)\n",
    "        else:\n",
    "            dataset = dataset.cache()\n",
    "    \n",
    "    dataset = dataset.shuffle(NUM_TOTAL_IMAGES)\n",
    "    \n",
    "    # Extraction: IO Intensive\n",
    "    dataset = dataset.map(get_bytes_label, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    # Transformation: CPU Intensive\n",
    "    dataset = dataset.map(process_image, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    \n",
    "    # Pipeline next iteration\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = build_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Attemp: No cache, no tricks\n",
    "\n",
    "In this first benchmark no caching mecanism is used and the images were read one by one from the bucket.\n",
    "\n",
    "The biggest problem here is to read 1000's of files one by one. This can really slow down the process.\\\n",
    "Let's call our \"timeit\" function to measure the time needed for the load. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "1000 batches: 81.02456021308899 s\n",
      "12.34194 Images/s\n"
     ]
    }
   ],
   "source": [
    "# Iterate throw this dataset for 100 elements.\n",
    "timeit(train_ds, batch_size=1, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, let's put some local cache in action\n",
    "\n",
    "Tf.data.Dataset implements a cache function. \n",
    "\n",
    "If no parameter is passad to the cache, it uses the memory of the host to cache the data. \\\n",
    "The problem is if your dataset is bigger than your host memory and you can't cache the Epoch in memory. In this case the cache won't help and we still have a bottleneck.\\\n",
    "It is also possible to cache the images in a local storage for reuse in future epochs. But in this case we are measuring the throughput from Cloud Storage and want to achieve the best performance possible.\n",
    "\n",
    "First let's test the throughput using cache in memory and than in as a local file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "1000 batches: 76.16763186454773 s\n",
      "13.12894 Images/s\n"
     ]
    }
   ],
   "source": [
    "# Memory\n",
    "train_cache_ds = build_dataset(dataset, cache=True)\n",
    "timeit(train_cache_ds, batch_size=1, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "1000 batches: 73.27346587181091 s\n",
      "13.64751 Images/s\n"
     ]
    }
   ],
   "source": [
    "# Local Cache File\n",
    "train_local_cache_ds = build_dataset(dataset, cache='./dog.tfcache')\n",
    "timeit(train_local_cache_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hum ...\n",
    "\n",
    "Ok, but no performance improvement?\n",
    "\n",
    "In this case, even using memory and local cache, the host VM is not able to fetch more data, mainly because of the amount of small files in Cloud Storage.\n",
    "\n",
    "To solve this problem we can follow some best practices for designing a performant TensorFlow data input pipeline (from the Tensorflow documentation [1]):\n",
    "\n",
    " - Use the prefetch transformation to overlap the work of a producer and consumer.\n",
    " - Parallelize the data reading transformation using the interleave transformation.\n",
    " - Parallelize the map transformation by setting the num_parallel_calls argument.\n",
    " - Use the cache transformation to cache data in memory during the first epoch\n",
    " - Vectorize user-defined functions passed in to the map transformation\n",
    " - Reduce memory usage when applying the interleave, prefetch, and shuffle transformations.\n",
    " \n",
    "But before we continue, let's do some tracing to understand what is going on.\n",
    "\n",
    "[1] https://www.tensorflow.org/guide/data_performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "1000 batches: 83.81774067878723 s\n",
      "11.93065 Images/s\n"
     ]
    }
   ],
   "source": [
    "tf.summary.trace_off()\n",
    "tf.summary.trace_on(graph=False, profiler=True)\n",
    "\n",
    "train_ds = build_dataset(dataset)\n",
    "timeit(train_ds, steps=1000)\n",
    "\n",
    "tf.summary.trace_export('Data Pipeline', profiler_outdir='/home/jupyter/tensorflow-data-pipeline/logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=/home/jupyter/tensorflow-data-pipeline/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>High Level View</th>\n",
    "    <th>Zoom View</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"https://storage.cloud.google.com/renatoleite-nb/images/trace1.png\"></td>\n",
    "    <td><img src=\"https://storage.cloud.google.com/renatoleite-nb/images/trace2.png\"></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two threads were created to read the files in parallel. \\\n",
    "The next step is to bundle together all the images in a TFRecord file, so let's do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TF.Record for speedup de reading process\n",
    "\n",
    "Up to now the images were read one by one, which demonstrated to be a very inefficient process. \\\n",
    "To mitigate this problem, one solution is to preprocess and write the images and labels to TFRecords files.\n",
    "\n",
    "In the following steps, the images are preprocessed and written to TFRecords.\n",
    "The following steps are followed:\n",
    " - Read the data from Cloud Storage\n",
    " - Decode the JPEG and resize the image\n",
    " - Encode the JPEG\n",
    " - Serialize the images into Bytes (tf.train.BytesList) and Labels into Ints (tf.train.Int64List)\n",
    " - Create a tf.Example with this two components and return a serialized string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download bytes from Cloud Storage\n",
    "def get_bytes_label_tfrecord(filepath, label):\n",
    "    raw_bytes = tf.io.read_file(filepath)\n",
    "    return raw_bytes, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Image\n",
    "def process_image_tfrecord(raw_bytes, label):\n",
    "    image = tf.io.decode_jpeg(raw_bytes, channels=3)\n",
    "    image = tf.image.resize(image, (224,224), method='nearest')\n",
    "    image = tf.io.encode_jpeg(image, optimize_size=True)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read images, preprocess and return a dataset\n",
    "def build_dataset_tfrecord(dataset):\n",
    "    \n",
    "    dataset = dataset.map(get_bytes_label_tfrecord, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.map(process_image_tfrecord, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_serialize_example(image, label):\n",
    "    \n",
    "    def _bytes_feature(value):\n",
    "        \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "        if isinstance(value, type(tf.constant(0))):\n",
    "            value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    def _float_feature(value):\n",
    "        \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "    def _int64_feature(value):\n",
    "        \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=value))    \n",
    "    \n",
    "    def serialize_example(image, label):\n",
    "        \n",
    "        feature = {\n",
    "            'image': _bytes_feature(image),\n",
    "            'label': _int64_feature(label)\n",
    "        }\n",
    "\n",
    "        example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        \n",
    "        return example_proto.SerializeToString()\n",
    "    \n",
    "    tf_string = serialize_example(image, label)\n",
    "\n",
    "    return tf_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function shards the dataset into batches of images and labels. \\\n",
    "For each shard, the images and labels are serialized and written to the TFRecord file.\n",
    "\n",
    "The TFRecordWriter allows the compression of files to some formas. One chosen here is GZIP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TFRecord with ~9000\n",
    "def create_tfrecord(ds, n_shards):\n",
    "\n",
    "    for i in range(n_shards):\n",
    "        batch = map(lambda x: tf_serialize_example(x[0],x[1]), ds.shard(n_shards, i)\n",
    "                    .apply(build_dataset_tfrecord)\n",
    "                    .as_numpy_iterator())\n",
    "        \n",
    "        with tf.io.TFRecordWriter('output_file-part-{i}.tfrecord'.format(i=i), 'GZIP') as writer:\n",
    "            print('Creating TFRecord ... output_file-part-{i}.tfrecord'.format(i=i))\n",
    "            for a in batch:\n",
    "                writer.write(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tfrecord(dataset, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consuming the TFRecord and Re-Running the Benchmark\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFRECORDS = 'gs://tf-data-pipeline/tfrecords/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a description of the features.\n",
    "feature_description = {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def _parse_function(example_proto):\n",
    "    # Parse the input `tf.Example` proto using the dictionary above.\n",
    "    return tf.io.parse_single_example(example_proto, feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = tf.io.gfile.glob(TFRECORDS)\n",
    "\n",
    "filenames_dataset = tf.data.Dataset.from_tensor_slices(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Image\n",
    "@tf.function\n",
    "def process_image_tfrecord(record):  \n",
    "    image = tf.io.decode_jpeg(record['image'], channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    \n",
    "    label = record['label']\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_tfrecord(filename):\n",
    "    return tf.data.TFRecordDataset(filename, compression_type='GZIP', num_parallel_reads=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_test(dataset, batch_size=BATCH_SIZE, cache=False):\n",
    "    \n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            dataset = dataset.cache(cache)\n",
    "        else:\n",
    "            dataset = dataset.cache()\n",
    "    \n",
    "    dataset = dataset.interleave(get_tfrecord, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    # dataset = dataset.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    # Transformation: CPU Intensive\n",
    "    dataset = dataset.map(process_image_tfrecord, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    \n",
    "    # Pipeline next iteration\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = build_dataset_test(filenames_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit(test_ds, steps=50000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
