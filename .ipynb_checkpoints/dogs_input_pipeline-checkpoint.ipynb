{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building High Performance Data Pipelines with tf.Data\n",
    "\n",
    "In this article we present some recipes on how to build a data input pipeline using Tensorflow, specially tf.data.\n",
    "It is recommended to read the first part, which defines the overall data and model, and then jump to any topic that interest you the most.\n",
    "\n",
    "This article uses the Stanford Dogs Dataset with ~20000 images and 120 classes [1].\n",
    "\n",
    "\n",
    "[1] Stanford Dataset - Dog Breeds\n",
    "\n",
    "[] https://colab.sandbox.google.com/gist/robieta/9463e86b5501541a441d431b9c4f1a1e/tf_world.ipynb\n",
    "\n",
    "## Step ONE\n",
    "\n",
    "Read images one by one from a Google Cloud Storage bucket (gs).\n",
    "\n",
    "Note that this may not be very efficient as we have a lot of small files to read (random reads).\n",
    "\n",
    "\n",
    "### Second Attempt\n",
    "\n",
    "Consolidate images inside a TFRecord file. Use tf.examples protobuf to store all the bytes from images.\n",
    "\n",
    "### Third Attempt\n",
    "\n",
    "Consolidate images already pre processed, using Apache Beam and TFRecord IO transform.\n",
    "\n",
    "### Forth Attempt\n",
    "\n",
    "Use multiple GPUs to train our model.\n",
    "\n",
    "### Fifth Attempt\n",
    "\n",
    "Use Multiple workers to scale up the training.\n",
    "\n",
    "### Other\n",
    " - Mixed Precision (optimize computation, but not IO)\n",
    " - Change Batch Size\n",
    " - Distributed Training (Strategy)\n",
    "  - tf.distribute.MirroredStrategy\n",
    "  - tf.distribute.MultiWorkerMirroredStrategy\n",
    "  - tf.distribute.TPUStrategy\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import zeros\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable XLA jit graph compilation\n",
    "# Performance gains for fixed size images\n",
    "tf.config.optimizer.set_jit(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE = 'gs://renatoleite-tf-datapipeline-poc/*/*'\n",
    "RESOLUTION = (224,224)\n",
    "NUM_TOTAL_IMAGES = 24000\n",
    "IMG_SHAPE=(224,224,3)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels from folders\n",
    "path = 'gs://renatoleite-tf-datapipeline-poc/*'\n",
    "folders_name = tf.io.gfile.glob(path)\n",
    "\n",
    "labels = []\n",
    "for folder in folders_name:\n",
    "    labels.append(folder.split(sep='/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Label Map\n",
    "label_map = {labels[i]:i for i in range(len(labels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files in bucket\n",
    "filepath = 'gs://renatoleite-tf-datapipeline-poc/*/*'\n",
    "filepath = tf.io.gfile.glob(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to One hot encode the inputs\n",
    "def one_hot_encode(label_map, filepath):\n",
    "    dataset = dict()\n",
    "    \n",
    "    for i in range(len(filepath)):\n",
    "        encoding = zeros(len(label_map), dtype='uint8')\n",
    "        encoding[label_map[filepath[i].split(sep='/')[-2]]] = 1\n",
    "        \n",
    "        dataset.update({filepath[i]:list(encoding)})\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = one_hot_encode(label_map, filepath)\n",
    "dataset = [[k,v] for k,v in dataset.items()]\n",
    "\n",
    "features = [i[0] for i in dataset]\n",
    "labels = [i[1] for i in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset from Features and Labels\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download bytes from Cloud Storage\n",
    "def get_bytes_label(filepath, label):\n",
    "    raw_bytes = tf.io.read_file(filepath)\n",
    "    return raw_bytes, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Image\n",
    "def process_image(raw_bytes, label):\n",
    "    image = tf.io.decode_jpeg(raw_bytes, channels=3)\n",
    "    image = tf.image.resize(image, RESOLUTION)\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(dataset, batch_size=32):\n",
    "    dataset = dataset.shuffle(NUM_TOTAL_IMAGES)\n",
    "    \n",
    "    # Extraction: IO Intensive\n",
    "    dataset = dataset.map(get_bytes_label, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    # Transformation: CPU Intensive\n",
    "    dataset = dataset.map(process_image, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    \n",
    "    # Pipeline next iteration\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tracing execution\n",
    "tf.summary.trace_on(profiler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "base_model = tf.keras.applications.ResNet50V2(weights='imagenet', \n",
    "                                         input_shape=IMG_SHAPE,\n",
    "                                         include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(label_map))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.01),\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50v2 (Model)           (None, 7, 7, 2048)        23564800  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                6422592   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               7800      \n",
      "=================================================================\n",
      "Total params: 29,995,192\n",
      "Trainable params: 6,430,392\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 644 steps\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:Trace already enabled\n",
      " 37/644 [>.............................] - ETA: 13:37 - loss: 2.4998 - accuracy: 0.9520"
     ]
    }
   ],
   "source": [
    "model.fit(dataset, epochs=2, callbacks=[tensorboard_callback], steps_per_epoch=644)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_one_image(filepath):\n",
    "    image = tf.io.read_file(filepath)\n",
    "    image = tf.io.decode_jpeg(image)\n",
    "    \n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    image = tf.image.resize(image, (224,224))\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/home/jupyter/dog2.jpg'\n",
    "dog = read_one_image(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dog = model(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop tracing execution\n",
    "tf.summary.trace_export(name='Loading Data', profiler_outdir='/home/jupyter/logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir /home/jupyter/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
