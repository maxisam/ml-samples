{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_Ldxu6AsEwG"
   },
   "source": [
    "# Dataset\n",
    " - Fazer download do dataset\n",
    " - Plotar um conjunto de imagens para ver o que elas se parecem e quais os labels que ela recebe.\n",
    "\n",
    "Kaggle Dataset = Planet Understanding the Amazon from Space\n",
    "\n",
    "[Planet: Understanting the Amazon from Space](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space)\n",
    "\n",
    " - Tensorflow: Usar a função de tk.keras.util ou tf.io ou tf.data para fazer o download do arquivo e unzip dele.\n",
    " - Sabendo que cada imagem tem mais de 1 lable, como iremos montar nosso dataset? Como o tf.data interpreta múltiplos labels?\n",
    " - Como o Keras no modelo irá tratar isso em termos do Loss e Optimizer?\n",
    "\n",
    "Labels\n",
    " - Carregar o CSV e fazer um print para entender como está estruturado os labels.\n",
    " - Criar um dataset desse conjunto de imagens e labels.\n",
    "\n",
    "tf.Data\n",
    " - Criar o dataset com as imagens e labels.\n",
    " - Para cada imagem aplicar as seguintes transformações:\n",
    "  - Flip Vertical\n",
    "  - Max Lightining = 0.1\n",
    "  - Max Zoom = 1.05\n",
    "  - Max Warp = 0.\n",
    " - Split de 20% do dataset para validação (deixar umas imagens de fora para test)\n",
    " - Batch Size de 128 imagens\n",
    " - Repeat do dataset e determinar o número de steps\n",
    " - Normalizar para entre 0 e 1.\n",
    " \n",
    "Nesse dataset, como faço para determinar a quantidade de imagens, quantos labels existem, quais as classes, etc.?\n",
    "\n",
    " - Como fazemos para criar datasets para Object Detection? Image Segmentation? Multi label? Text? Corpus?\n",
    "\n",
    "### Future Model\n",
    "\n",
    "Criar um modelo para reconhecer o que é um prédio, uma casa, uma casa em construção, um barrac, etc.\n",
    "Criar um dataset com o Planet para detectar isso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XjPKSRTy8l4r"
   },
   "source": [
    "# Model\n",
    " - Usar o ResNet50 como base\n",
    "\n",
    "Métricas Customizadas\n",
    " - Accuracy\n",
    " - F-Score\n",
    "  - Relembrar o que é Precission, Accuracy, Recall e F(n)-Score\n",
    " - Threashold de 0.2 para o FScore\n",
    "\n",
    "Método\n",
    " - Model.fit \n",
    " - Gradient Tapes\n",
    "\n",
    "?? Num modelo de classificação, como coloco um threashold na classificação.? Isso seria no Loss? Ou em alguma métrica específica?\n",
    "\n",
    "Learning Rate\n",
    " - Achar o LR ideal baseado no decay do plot da função do LR x epochs.\n",
    "\n",
    "Callbacks\n",
    " - Criar os seguintes callbacks (quando apropriado):\n",
    "  - ModelSaveweights\n",
    "  - LearningRateScheduler\n",
    "  - EarlyStop\n",
    "\n",
    "Save\n",
    " - Salvar o modelo em um arquivo .h5, checkpoint e SavedModel.\n",
    " - Carregar todos eles e lembrar as diferenças entre eles.\n",
    "\n",
    "### Performance\n",
    "\n",
    " - Com ResNet50 devemos ter pelo menos 92% de F2-Score.\n",
    "  - Como melhorar isso?\n",
    " - Podemos treinar o resto da rede para customizar ainda mais o resultado.\n",
    " - Mudar o batch size e fazer o RESHAPE para 256 x 256 da imagem.\n",
    "\n",
    "Começar o treinamento com imagens 128 x 128 e usar os mesmos weights já treinados para imagens com 256 x 256.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FB98TSvUZDjS"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDCDujTmQDfH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "abbhlpuoK_gO"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1019,
     "status": "ok",
     "timestamp": 1582892490033,
     "user": {
      "displayName": "Renato Leite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCcpGTVtWJSJsdfArIod76mBazk0Z-3wTxm3KyO=s64",
      "userId": "15440836296443467523"
     },
     "user_tz": 180
    },
    "id": "SqPXHYiJmmd-",
    "outputId": "f5f48fa4-67ac-4668-957c-42617aa6704e"
   },
   "outputs": [],
   "source": [
    "# Read filenames and labels\n",
    "ds_train = pd.read_csv('/root/.fastai/data/planet_sample/labels.csv')\n",
    "\n",
    "# Print first 5 lines\n",
    "ds_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GwCkY24sZGK0"
   },
   "source": [
    "# Prepare Dataset for Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PngDzCl894hC"
   },
   "outputs": [],
   "source": [
    "# Create a list of unique labels (set)\n",
    "labels = set()\n",
    "for i in ds_train['tags']:\n",
    "    labels.update(i.split(sep=' '))\n",
    "\n",
    "labels = list(labels)\n",
    "labels.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LxFKsiBBBMC5"
   },
   "outputs": [],
   "source": [
    "def create_tag_mapping(ds_train):\n",
    "    labels = set()\n",
    "    for i in ds_train['tags']:\n",
    "        labels.update(i.split(sep=' '))\n",
    "\n",
    "    labels = list(labels)\n",
    "    labels.sort()\n",
    "\n",
    "    label_map = {labels[i]:i for i in range(len(labels))}\n",
    "    inv_label_map = {i:labels[i] for i in range(len(labels))}\n",
    "\n",
    "    return label_map, inv_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xEeU4EcnCL7I"
   },
   "outputs": [],
   "source": [
    "def create_file_mapping(ds_train):\n",
    "    mapping = dict()\n",
    "    for i in range(len(ds_train)):\n",
    "        name, tags = ds_train['image_name'][i], ds_train['tags'][i]\n",
    "        name = '/root/.fastai/data/planet_sample/train/' + name + '.jpg'\n",
    "        mapping[name] = tags.split(' ')\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "otA0vmrDNM1a"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(tag_mapping, file_mapping):\n",
    "    dataset = dict()\n",
    "    for filename, tags in file_mapping.items():\n",
    "        encoding = np.zeros(len(tag_mapping), dtype='uint8')\n",
    "        for tag in tags:\n",
    "            encoding[tag_mapping[tag]] = 1\n",
    "        dataset.update({filename:list(encoding)})\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "My39vaI6Y4EA"
   },
   "outputs": [],
   "source": [
    "tag_mapping, inv_label_map = create_tag_mapping(ds_train)\n",
    "file_mapping = create_file_mapping(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a7XkUzwRQouH"
   },
   "outputs": [],
   "source": [
    "dataset = one_hot_encode(tag_mapping, file_mapping)\n",
    "dataset = [[k,v] for k,v in dataset.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BpTMI8zwlPar"
   },
   "outputs": [],
   "source": [
    "features = [i[0] for i in dataset]\n",
    "labels = [i[1] for i in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42rmzw-0Bpwc"
   },
   "outputs": [],
   "source": [
    "# Quick function to convert image to jpg\n",
    "def convert_to_jpg(filename):\n",
    "    im = Image.open(filename)\n",
    "    rgb_im = im.convert('RGB')\n",
    "    rgb_im.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lFY4k5bCFbX1"
   },
   "outputs": [],
   "source": [
    "# Loop over list with filenames and convert to jpeg\n",
    "for filename in features:\n",
    "    convert_to_jpg(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Poj8F80NZJz8"
   },
   "source": [
    "# Create Tf.data.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n31uTCuqgtsB"
   },
   "outputs": [],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices((features, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eOIQ6WDuK_Wb"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(feature, label):\n",
    "    # Load raw data to uint8\n",
    "    img = tf.io.read_file(feature)\n",
    "    # convert jpeg to uint tensor\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    # convert to float in [0,1] range\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to desired size\n",
    "    img = tf.image.resize(img, [224,224])\n",
    "    \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYLWqYt4J7GS"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ELWZKlwbg1_W"
   },
   "outputs": [],
   "source": [
    "labeled_ds = tf_dataset.map(preprocess_data, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9VrZP808KE1P"
   },
   "outputs": [],
   "source": [
    "def prepare_training(ds, cache=True, shuffle_buffer_size=1000):\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    ds = ds.repeat().batch(32)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ETTxecqANTr3"
   },
   "outputs": [],
   "source": [
    "train_ds = prepare_training(labeled_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HqAhh2BjNerh"
   },
   "outputs": [],
   "source": [
    "def show_batch(image, label):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        plt.imshow(image[n])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jZt5N0FxEb54"
   },
   "source": [
    "# Quick Visualization of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4294,
     "status": "ok",
     "timestamp": 1582898432768,
     "user": {
      "displayName": "Renato Leite",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCcpGTVtWJSJsdfArIod76mBazk0Z-3wTxm3KyO=s64",
      "userId": "15440836296443467523"
     },
     "user_tz": 180
    },
    "id": "nmd03lPtP-8X",
    "outputId": "12d46b48-c004-4cae-a62c-176f073e4fe9"
   },
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_ds))\n",
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sjhmyOrpGafZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNUnVxJzzRI0R5no4UIvKTz",
   "name": "Lesson 3 - Multi-Label Image Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
