{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List files from Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_blobs(bucket_name, prefix):\n",
    "    \"\"\"Lists all the blobs in the bucket.\"\"\"\n",
    "    images_paths = []\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Note: Client.list_blobs requires at least package version 1.17.0.\n",
    "    blobs = storage_client.list_blobs(bucket_name, prefix=prefix)\n",
    "\n",
    "    for blob in blobs:\n",
    "        images_paths.append(blob.name)\n",
    "        \n",
    "    return images_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'datasets/xray-chest-nih/images'\n",
    "bucket_name = 'tensorflow-samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_paths = list_blobs(bucket_name, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Images Paths to create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_prefix = 'gs://tensorflow-samples/datasets/xray-chest-nih/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = 'gs://tensorflow-samples/datasets/xray-chest-nih/labels/labels.csv'\n",
    "df_files = pd.read_csv(labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter images with label Effusion\n",
    "effusion_images = df_files[df_files['Finding Labels'].str.contains('Effusion')]\n",
    "\n",
    "# Keep only image name and label\n",
    "effusion_images = effusion_images[['Image Index','Finding Labels']]\n",
    "effusion_images['Image Index'] = images_prefix + effusion_images['Image Index']\n",
    "effusion_images['Finding Labels'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter images with label No Finding\n",
    "nofindings_images = df_files[df_files['Finding Labels'].str.contains('No Finding')]\n",
    "\n",
    "# Keep only image name and label\n",
    "nofindings_images = nofindings_images[['Image Index','Finding Labels']]\n",
    "nofindings_images['Image Index'] = images_prefix + nofindings_images['Image Index']\n",
    "nofindings_images['Finding Labels'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only a subset of the main dataset\n",
    "nofindings_images = nofindings_images.iloc[:20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's concatenate the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "effusion_range = len(effusion_images)\n",
    "nofindings_range = len(nofindings_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = list(effusion_images['Image Index'][:int(effusion_range*0.90)])\n",
    "train_images = train_images + list(nofindings_images['Image Index'][:int(nofindings_range*0.90)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = list(effusion_images['Finding Labels'][:int(effusion_range*0.90)]) \n",
    "train_labels = train_labels + list(nofindings_images['Finding Labels'][:int(nofindings_range*0.90)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Val Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = list(effusion_images['Image Index'][int(effusion_range*0.90):int(effusion_range*0.97)])\n",
    "val_images = val_images + list(nofindings_images['Image Index'][int(nofindings_range*0.90):int(nofindings_range*0.97)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = list(effusion_images['Finding Labels'][int(effusion_range*0.90):int(effusion_range*0.97)]) \n",
    "val_labels = val_labels + list(nofindings_images['Finding Labels'][int(nofindings_range*0.90):int(nofindings_range*0.97)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = list(effusion_images['Image Index'][int(effusion_range*0.97):])\n",
    "test_images = test_images + list(nofindings_images['Image Index'][int(nofindings_range*0.97):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = list(effusion_images['Finding Labels'][int(effusion_range*0.97):]) \n",
    "test_labels = test_labels + list(nofindings_images['Finding Labels'][int(nofindings_range*0.97):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29985\n",
      "2332\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_images))\n",
    "print(len(val_images))\n",
    "print(len(test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate TFRecord with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's create a tf.data.dataset from file paths\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(buffer_size=len(train_images))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_tfrecord(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_png(image)\n",
    "    image = tf.image.resize(image, [512,512], method='nearest')\n",
    "    image = tf.expand_dims(image[:,:,0], -1)\n",
    "    image = tf.image.encode_png(image)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_tfrecord(paths_dataset):\n",
    "    dataset = paths_dataset.map(process_image_tfrecord, num_parallel_calls=AUTOTUNE)    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_serialize_example(image, label):\n",
    "    \n",
    "    def _bytes_feature(value):\n",
    "        \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "        if isinstance(value, type(tf.constant(0))):\n",
    "            value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    def _float_feature(value):\n",
    "        \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "    def _int64_feature(value):\n",
    "        \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))    \n",
    "    \n",
    "    def serialize_example(image, label):\n",
    "        \n",
    "        feature = {\n",
    "            'image': _bytes_feature(image),\n",
    "            'label': _int64_feature(label)\n",
    "        }\n",
    "\n",
    "        example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        \n",
    "        return example_proto.SerializeToString()\n",
    "    \n",
    "    tf_string = serialize_example(image, label)\n",
    "\n",
    "    return tf_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TFRecord with `n_shards` shards (GZIP)\n",
    "def create_tfrecord(ds, n_shards, name):\n",
    "\n",
    "    for i in range(n_shards):\n",
    "        batch = map(lambda x: tf_serialize_example(x[0],x[1]), ds.shard(n_shards, i)\n",
    "                    .apply(build_dataset_tfrecord)\n",
    "                    .make_one_shot_iterator())\n",
    "        \n",
    "        with tf.io.TFRecordWriter('{name}-output_file-part-{i}.tfrecord'.format(i=i, name=name), 'GZIP') as writer:\n",
    "            print('Creating TFRecord ... output_file-part-{i}.tfrecord'.format(i=i))\n",
    "            for a in batch:\n",
    "                writer.write(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tfrecord(train_dataset, 30, 'train')\n",
    "create_tfrecord(val_dataset, 6, 'val')\n",
    "create_tfrecord(test_dataset, 4, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp train*.tfrecord gs://tensorflow-samples/datasets/xray-chest-nih/tfrecords/train/\n",
    "!gsutil -m cp val*.tfrecord gs://tensorflow-samples/datasets/xray-chest-nih/tfrecords/val/\n",
    "!gsutil -m cp test*.tfrecord gs://tensorflow-samples/datasets/xray-chest-nih/tfrecords/test/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consume TFRecords and create tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TFRECORDS = 'gs://tensorflow-samples/datasets/xray-chest-nih/tfrecords/train/*'\n",
    "VAL_TFRECORDS = 'gs://tensorflow-samples/datasets/xray-chest-nih/tfrecords/val/*'\n",
    "TEST_TFRECORDS = 'gs://tensorflow-samples/datasets/xray-chest-nih/tfrecords/test/*'\n",
    "BATCH_SIZE = 32\n",
    "STEPS_TRAIN = int(len(train_images)/BATCH_SIZE)\n",
    "STEPS_VAL = int(len(val_images)/BATCH_SIZE)\n",
    "STEPS_TEST = int(len(test_images)/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def parse_function(example_proto):\n",
    "    # Parse the input `tf.Example` proto using the dictionary above.\n",
    "    \n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    \n",
    "    return tf.io.parse_example(example_proto, feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def process_image(record):\n",
    "    image = tf.map_fn(tf.io.decode_png, record['image'], dtype=tf.uint8)\n",
    "    image = tf.map_fn(lambda image: \n",
    "                      tf.image.convert_image_dtype(image, dtype=tf.float32), image, dtype=tf.float32)\n",
    "    \n",
    "    label = record['label']\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert grayscale => RGB to use InceptionV3\n",
    "# NOT USED\n",
    "@tf.function\n",
    "def grayscale_to_rgb(images, labels):\n",
    "    images = tf.image.grayscale_to_rgb(images)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_tfrecord(filename):\n",
    "    return tf.data.TFRecordDataset(filename, compression_type='GZIP', \n",
    "                                   num_parallel_reads=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(dataset, batch_size=BATCH_SIZE):\n",
    "    \n",
    "    dataset = dataset.interleave(get_tfrecord, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.map(process_image, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    dataset = dataset.repeat()\n",
    "    # Pipeline next iteration\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files= tf.io.gfile.glob(TRAIN_TFRECORDS)\n",
    "val_files= tf.io.gfile.glob(VAL_TFRECORDS)\n",
    "test_files= tf.io.gfile.glob(TEST_TFRECORDS)\n",
    "\n",
    "train_filenames_dataset = tf.data.Dataset.from_tensor_slices(train_files)\n",
    "val_filenames_dataset = tf.data.Dataset.from_tensor_slices(val_files)\n",
    "test_filenames_dataset = tf.data.Dataset.from_tensor_slices(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = build_dataset(train_filenames_dataset)\n",
    "val_dataset = build_dataset(val_filenames_dataset)\n",
    "test_dataset = build_dataset(test_filenames_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (512,512,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Functional API\n",
    "# def create_model(img_shape=IMG_SHAPE):\n",
    "    \n",
    "#     # Define input and shapes\n",
    "#     img_inputs = tf.keras.Input(shape=img_shape)\n",
    "\n",
    "#     # 1th group\n",
    "#     x = tf.keras.layers.Conv2D(64, (5,5), use_bias=False)(img_inputs)\n",
    "#     x = tf.keras.layers.BatchNormalization()(x)\n",
    "#     x = tf.keras.layers.Activation('relu')(x)\n",
    "#     x = tf.keras.layers.MaxPool2D((3,3),(2,2))(x)\n",
    "\n",
    "#     # 2nd group\n",
    "#     x = tf.keras.layers.Conv2D(128, (5,5), use_bias=False)(x)\n",
    "#     x = tf.keras.layers.BatchNormalization()(x)\n",
    "#     x = tf.keras.layers.Activation('relu')(x)\n",
    "#     x = tf.keras.layers.MaxPool2D((3,3),(2,2))(x)\n",
    "\n",
    "#     # 3rd group\n",
    "#     x = tf.keras.layers.Conv2D(256, (5,5), use_bias=False)(x)\n",
    "#     x = tf.keras.layers.BatchNormalization()(x)\n",
    "#     x = tf.keras.layers.Activation('relu')(x)\n",
    "#     x = tf.keras.layers.MaxPool2D((3,3),(2,2))(x)\n",
    "\n",
    "#     # 4th group\n",
    "#     x = tf.keras.layers.Conv2D(512, (5,5), use_bias=False)(x)\n",
    "#     x = tf.keras.layers.BatchNormalization()(x)\n",
    "#     x = tf.keras.layers.Activation('relu')(x)\n",
    "#     x = tf.keras.layers.MaxPool2D((3,3),(2,2))(x)\n",
    "\n",
    "#     # 5th group\n",
    "#     x = tf.keras.layers.GlobalAvgPool2D()(x)\n",
    "\n",
    "#     # Classification\n",
    "#     outputs = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "#     # Create model\n",
    "#     model = tf.keras.Model(img_inputs, outputs)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential API\n",
    "def create_model(img_shape=IMG_SHAPE):\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        # 1th group\n",
    "        tf.keras.layers.Conv2D(64, (5,5), use_bias=False, input_shape=img_shape),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.MaxPool2D((3,3),(2,2)),\n",
    "\n",
    "        # 2nd group\n",
    "        tf.keras.layers.Conv2D(128, (5,5), use_bias=False),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.MaxPool2D((3,3),(2,2)),\n",
    "\n",
    "        # 3rd group\n",
    "        tf.keras.layers.Conv2D(256, (5,5), use_bias=False),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.MaxPool2D((3,3),(2,2)),\n",
    "\n",
    "        # 4th group\n",
    "        tf.keras.layers.Conv2D(512, (5,5), use_bias=False),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.MaxPool2D((3,3),(2,2)),\n",
    "\n",
    "        # 5th group\n",
    "        tf.keras.layers.GlobalAvgPool2D(),\n",
    "\n",
    "        # Classification\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckp = tf.keras.callbacks.ModelCheckpoint(filepath='mymodel_{epoch}',\n",
    "                                               save_best_only=True, monitor='val_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    if epoch < 6:\n",
    "        return (epoch*0.1*(32/256)/5)\n",
    "    elif epoch >= 6 and epoch < 30:\n",
    "        return (0.1*(32/256))\n",
    "    elif epoch >= 30 and epoch < 60:\n",
    "        return (0.1*(32/256))/10\n",
    "    elif epoch >= 60 and epoch < 90:\n",
    "        return (0.1*(32/256))/100\n",
    "    else:\n",
    "        return (0.1*(32/256))/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_sched = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        optimizer = self.model.optimizer\n",
    "        print('\\nLearning rate for epoch {} is {}'.format(epoch + 1, optimizer.lr.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(momentum=0.9),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model (Distributed?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_strategy(distributed=False):\n",
    "    if distributed:\n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "        \n",
    "        with strategy.scope():\n",
    "            model = create_model()\n",
    "            model = compile_model(model)\n",
    "            \n",
    "    else:\n",
    "        model = create_model()\n",
    "        model = compile_model(model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_strategy(distributed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./mymodel_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 937 steps, validate for 72 steps\n",
      "Epoch 1/5\n",
      "INFO:tensorflow:batch_all_reduce: 14 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 14 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "936/937 [============================>.] - ETA: 0s - loss: 0.8195 - acc: 0.4360\n",
      "Learning rate for epoch 1 is 0.0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.86954, saving model to mymodel_1\n",
      "937/937 [==============================] - 170s 181ms/step - loss: 0.8194 - acc: 0.4362 - val_loss: 0.8695 - val_acc: 0.3216\n",
      "Epoch 2/5\n",
      "936/937 [============================>.] - ETA: 0s - loss: 0.5642 - acc: 0.6938\n",
      "Learning rate for epoch 2 is 0.0024999999441206455\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.86954\n",
      "937/937 [==============================] - 151s 161ms/step - loss: 0.5641 - acc: 0.6939 - val_loss: 2.0854 - val_acc: 0.4058\n",
      "Epoch 3/5\n",
      "936/937 [============================>.] - ETA: 0s - loss: 0.5150 - acc: 0.7369\n",
      "Learning rate for epoch 4 is 0.007499999832361937\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.86954\n",
      "937/937 [==============================] - 151s 161ms/step - loss: 0.5149 - acc: 0.7371 - val_loss: 5.8268 - val_acc: 0.4045\n",
      "Epoch 5/5\n",
      "936/937 [============================>.] - ETA: 0s - loss: 0.4955 - acc: 0.7533\n",
      "Learning rate for epoch 5 is 0.009999999776482582\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.86954\n",
      "937/937 [==============================] - 151s 161ms/step - loss: 0.4954 - acc: 0.7533 - val_loss: 1.7160 - val_acc: 0.4041\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=5, \n",
    "                    validation_data=val_dataset,\n",
    "                    steps_per_epoch=STEPS_TRAIN,\n",
    "                    validation_steps=STEPS_VAL,\n",
    "                    callbacks=[PrintLR(), lr_sched, model_ckp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 4s 133ms/step - loss: 1.7415 - acc: 0.4022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.741519907669675, 0.40221775]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset, steps=STEPS_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'export', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f753a687d50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "## Convert our Keras model to an estimator and then export to SavedModel\n",
    "keras_estimator = tf.keras.estimator.model_to_estimator(keras_model=model, model_dir='export')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img_bytes(img_bytes, height, width, color_depth):\n",
    "    features = tf.squeeze(img_bytes, axis=1, name='input_squeeze')\n",
    "    float_pixels = tf.map_fn(\n",
    "        lambda img_string: tf.io.decode_image(\n",
    "            img_string, \n",
    "            channels=color_depth,\n",
    "            dtype=tf.float32\n",
    "        ),\n",
    "        features,\n",
    "        dtype=tf.float32,\n",
    "        name='input_convert'\n",
    "    )\n",
    "\n",
    "    tf.Tensor.set_shape(float_pixels, (None, height, width, color_depth))\n",
    "    float_pixels = tf.identity(float_pixels, name='input_pixels')\n",
    "\n",
    "    return float_pixels\n",
    "\n",
    "def serving_input_receiver_fn():\n",
    "    img_bytes = tf.placeholder(shape=(None,1), dtype=tf.string)\n",
    "    img_float = decode_img_bytes(img_bytes, 512, 512, 1)\n",
    "    return tf.estimator.export.ServingInputReceiver({'conv2d_4_input': img_float}, {'conv2d_4_input': img_bytes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from export/keras/keras_model.ckpt\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: gs://tensorflow-samples/datasets/xray-chest-nih/explanations/temp-b'1588188868'/saved_model.pb\n",
      "Model exported to:  gs://tensorflow-samples/datasets/xray-chest-nih/explanations/1588188868\n"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME = 'tensorflow-samples/datasets/xray-chest-nih'\n",
    "export_path = keras_estimator.export_saved_model(\n",
    "  'gs://' + BUCKET_NAME + '/explanations',\n",
    "  serving_input_receiver_fn\n",
    ").decode('utf-8')\n",
    "print(\"Model exported to: \", export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://tensorflow-samples/datasets/xray-chest-nih/explanations/1588188868'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29 19:34:45.519787: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['conv2d_4_input'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1, 1)\n",
      "        name: Placeholder:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['dense_1'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: dense_1/BiasAdd:0\n",
      "  Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir $export_path --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_metadata = {\n",
    "    \"inputs\": {\n",
    "      \"data\": {\n",
    "        \"input_tensor_name\": \"input_pixels:0\",\n",
    "        \"modality\": \"image\",\n",
    "        \"input_baselines\": [0,1]\n",
    "      }\n",
    "    },\n",
    "    \"outputs\": {\n",
    "      \"probability\": {\n",
    "        \"output_tensor_name\": \"dense_1/BiasAdd:0\"\n",
    "      }\n",
    "    },\n",
    "  \"framework\": \"tensorflow\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Write the json to a local file\n",
    "with open('explanation_metadata.json', 'w') as output_file:\n",
    "    json.dump(explanation_metadata, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://explanation_metadata.json [Content-Type=application/json]...\n",
      "/ [1 files][  209.0 B/  209.0 B]                                                \n",
      "Operation completed over 1 objects/209.0 B.                                      \n"
     ]
    }
   ],
   "source": [
    "# Copy this file into the GCS location with our SavedModel assets\n",
    "!gsutil cp explanation_metadata.json $export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'xray_explain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model if it doesn't exist yet (you only need to run this once)\n",
    "!gcloud ai-platform models create $MODEL --enable-logging --regions=us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each time you create a version the name should be unique\n",
    "IG_VERSION = 'v_09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Using endpoint [https://ml.googleapis.com/]\n",
      "Explanations reflect patterns in your model, but don't necessarily reveal fundamental relationships about your data population. See https://cloud.google.com/ml-engine/docs/ai-explanations/limitations for more information.\n",
      "Creating version (this might take a few minutes)......done.                    \n"
     ]
    }
   ],
   "source": [
    "# Create the version with gcloud\n",
    "!gcloud beta ai-platform versions create $IG_VERSION \\\n",
    "--model $MODEL \\\n",
    "--origin $export_path \\\n",
    "--runtime-version 1.15 \\\n",
    "--framework TENSORFLOW \\\n",
    "--python-version 3.7 \\\n",
    "--machine-type n1-standard-4 \\\n",
    "--explanation-method integrated-gradients \\\n",
    "--num-integral-steps 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Using endpoint [https://ml.googleapis.com/]\n",
      "createTime: '2020-04-29T19:52:19Z'\n",
      "deploymentUri: gs://tensorflow-samples/datasets/xray-chest-nih/explanations/1588188868\n",
      "etag: FDZtZ67ohDk=\n",
      "explanationConfig:\n",
      "  integratedGradientsAttribution:\n",
      "    numIntegralSteps: 25\n",
      "framework: TENSORFLOW\n",
      "isDefault: true\n",
      "lastUseTime: '2020-04-29T21:32:46Z'\n",
      "machineType: n1-standard-4\n",
      "name: projects/cool-ml-demos/models/xray_explain/versions/v_09\n",
      "pythonVersion: '3.7'\n",
      "runtimeVersion: '1.15'\n",
      "state: READY\n"
     ]
    }
   ],
   "source": [
    "# Make sure the IG model deployed correctly. State should be `READY` in the following log\n",
    "!gcloud ai-platform versions describe $IG_VERSION --model $MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Predictions and explanations on deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://tensorflow-samples/datasets/xray-chest-nih/images/00000003_000.png...\n",
      "/ [1 files][439.5 KiB/439.5 KiB]                                                \n",
      "Operation completed over 1 objects/439.5 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://tensorflow-samples/datasets/xray-chest-nih/images/00000003_000.png ./examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from base64 import b64encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the images to what our model is expecting (192,192)\n",
    "test_filenames = []\n",
    "\n",
    "images = ['00000001_000.png','00000002_000.png','00000003_000.png']\n",
    "\n",
    "for i in images:\n",
    "    img_path = '/home/jupyter/ml-samples/googlecloud/explanations/xray/examples/' + i\n",
    "    with PIL.Image.open(img_path) as ex_img:\n",
    "        resize_img = ex_img.resize([512,512])\n",
    "        resize_img.save(img_path)\n",
    "        test_filenames.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare our prediction JSON to send to our Cloud model\n",
    "instances = []\n",
    "!rm xray-data.txt\n",
    "\n",
    "for i in test_filenames:\n",
    "    with open(i, 'rb') as example_img:\n",
    "        b64str = b64encode(example_img.read()).decode('utf-8')\n",
    "        with open('xray-data.txt', 'a') as outfile:\n",
    "            json.dump({'conv2d_4_input': [{'b64': b64str}]}, outfile)\n",
    "            outfile.write('\\n')\n",
    "        instances.append({'conv2d_4_input': [{'b64': b64str}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an AI Explanation request with gcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a9027e6becca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# IG EXPLANATIONS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mig_explanations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gcloud beta ai-platform explain --model $MODEL --version $IG_VERSION --json-instances='xray-data.txt'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mig_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mig_explanations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# IG EXPLANATIONS\n",
    "ig_explanations = !gcloud beta ai-platform explain --model $MODEL --version $IG_VERSION --json-instances='xray-data.txt'\n",
    "ig_response = json.loads(ig_explanations.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WARNING: Using endpoint [https://ml.googleapis.com/] {   \"error\": \"Explainability failed with exception: <_InactiveRpcError of RPC that terminated with:\\\\n\\\\tstatus = StatusCode.UNAVAILABLE\\\\n\\\\tdetails = \\\\\"upstream connect error or disconnect/reset before headers. reset reason: connection termination\\\\\"\\\\n\\\\tdebug_error_string = \\\\\"{\\\\\"created\\\\\":\\\\\"@1588284492.303774434\\\\\",\\\\\"description\\\\\":\\\\\"Error received from peer ipv4:10.59.253.192:8500\\\\\",\\\\\"file\\\\\":\\\\\"src/core/lib/surface/call.cc\\\\\",\\\\\"file_line\\\\\":1056,\\\\\"grpc_message\\\\\":\\\\\"upstream connect error or disconnect/reset before headers. reset reason: connection termination\\\\\",\\\\\"grpc_status\\\\\":14}\\\\\"\\\\n>\" }'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ig_explanations.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = !gcloud ai-platform predict --model $MODEL --version $IG_VERSION --json-instances='xray-data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WARNING: Using endpoint [https://ml.googleapis.com/]',\n",
       " '{',\n",
       " '  \"error\": \"Explainability failed with exception: <_InactiveRpcError of RPC that terminated with:\\\\n\\\\tstatus = StatusCode.UNAVAILABLE\\\\n\\\\tdetails = \\\\\"upstream connect error or disconnect/reset before headers. reset reason: connection termination\\\\\"\\\\n\\\\tdebug_error_string = \\\\\"{\\\\\"created\\\\\":\\\\\"@1588284492.303774434\\\\\",\\\\\"description\\\\\":\\\\\"Error received from peer ipv4:10.59.253.192:8500\\\\\",\\\\\"file\\\\\":\\\\\"src/core/lib/surface/call.cc\\\\\",\\\\\"file_line\\\\\":1056,\\\\\"grpc_message\\\\\":\\\\\"upstream connect error or disconnect/reset before headers. reset reason: connection termination\\\\\",\\\\\"grpc_status\\\\\":14}\\\\\"\\\\n>\"',\n",
       " '}']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ig_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ERROR: (gcloud.ai-platform.predict) argument --model: expected one argument',\n",
       " 'Usage: gcloud ai-platform predict --model=MODEL (--json-instances=JSON_INSTANCES | --json-request=JSON_REQUEST | --text-instances=TEXT_INSTANCES) [optional flags]',\n",
       " '  optional flags may be  --help | --json-instances | --json-request |',\n",
       " '                         --signature-name | --text-instances | --version',\n",
       " '',\n",
       " 'For detailed information on this command and its flags, run:',\n",
       " '  gcloud ai-platform predict --help']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
